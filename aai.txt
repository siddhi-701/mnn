PRACTICAL NO. 01

Aim:- Design an Expert system using AIML

Code: -
1.	“std-startup.xml” File
<aiml version="1.0.1" encoding="UTF-8">
<!-- std-startup.xml -->
<!-- Category is an atomic AIML unit -->
<category>
<!-- Pattern to match in user input -->
<!-- If user enters "LOAD AIML B" -->
<pattern>LOAD AIML B</pattern>
<!-- Template is the response to the pattern -->
<!-- This learn an aiml file -->
<template>
<learn>basic_chat.aiml</learn>
<!-- You can add more aiml files here -->
<!--<learn>more_aiml.aiml</learn>-->
</template>
</category>
</aiml>

2.	“basic_chat.aiml” File
<aiml version="1.0.1" encoding="UTF-8">
<!-- basic_chat.aiml -->
<category>
<pattern>HELLO *</pattern>
<template> Well, hello Brij!
</template>
</category>
<category>
<pattern>what are you doing</pattern>
<template>
Well, Brij I'm Chatting with you!
</template>
</category>
<category>
<pattern>whats my full name</pattern>
<template>
Well, hello Brijnandan Gupta!
</template>
</category>
<category>
<pattern>Whats my nickname</pattern>
<template>
I think its Brij!
</template> 
</category>
<category>
<pattern>WHAT ARE YOU</pattern>
<template>
I'm a bot, and I'm silly!
</template>
</category>
<category>
<pattern>WHAT DO YOU DO</pattern>
<template>
I'm here to annoy you!
</template>
</category>
<category>
<pattern>Who am i</pattern>
<template>
You are Brijnandan you are Fatty.
</template>
</category>
</aiml>

3.	“simply.py” File
import aiml
kernel = aiml.Kernel()
kernel.learn('C:/Users/Brijnandan/Desktop/Msc/AAI Practical/SimpleAIMLBot/std-startup.xml') kernel.respond('LOAD AIML B')
while True:
input_text = input(">Human: ") response = kernel.respond(input_text)
print(">Bot: "+response)


Output :–


 
PRACTICAL NO. 02

Aim:- Design a bot using AIML

Code: - We need to create following three files.

1)	std-startup.xml
<aiml version="1.0.1" encoding="UTF-8">
<!-- std-startup.xml -->
<category>
<pattern>LOAD</pattern>
<template>
<learn>basic_chat.aiml</learn>
</template>
</category>
</aiml>

2)	basic_chat.aiml
<aiml version="1.0.1" encoding="UTF-8">
<!-- basic_chat.aiml -->
<category>
<pattern>HELLO I AM *</pattern>
<template> HELLO <set name="username"> <star/> </set> </template>
</category>
<category>
<pattern>I LIKE * COLOR</pattern>
<template><star index="1"/> is a nice color.</template>
</category>
<category>
<pattern>BYE</pattern>
<template> BYE <get name="username"/> THANKS FOR THE CONVERSATION.
</template>
</category>
</aiml>

3)	testbot.py
import aiml
kernel = aiml.Kernel()
kernel.learn("E:\\ai pracs\\std-startup.xml") 
kernel.respond("LOAD")
# Press CTRL-C to break this loop while True:
print( kernel.respond(input("Enter your message >> ")))
 
Aim:- Implement Bayes Theorem using Python
# calculate P(A|B) given P(A), P(B|A), P(B|not A)
def bayes_theorem(p_a, p_b_given_a, p_b_given_not_a): # calculate P(not A)
  not_a = 1 - p_a # calculate P(B)
  p_b = p_b_given_a * p_a + p_b_given_not_a * not_a # calculate P(A|B)
  p_a_given_b = (p_b_given_a * p_a) / p_b 
  return p_a_given_b
# P(A)
p_a = 0.0002 # P(B|A)
p_b_given_a = 0.85 # P(B|not A)
p_b_given_not_a = 0.05 # calculate P(A|B)
result = bayes_theorem(p_a, p_b_given_a, p_b_given_not_a) # summarize
print('P(A|B) = %.3f%%' % (result * 100)) 

Conditional Probability
import pandas as pd
df = pd.read_csv('/content/sample_data/student-mat.csv')
df.head(3)
len(df)
import numpy as np
df['grade_A'] = np.where(df['G3']*5 >= 80, 1, 0)

df['high_absenses'] = np.where(df['absences'] >= 10, 1, 0)
df['count'] = 1

df = df[['grade_A','high_absenses','count']] 
df.head()
pd.pivot_table(
df, values='count',
index=['grade_A'], columns=['high_absenses'], aggfunc=np.size, fill_value=0
)
P_A = (35 + 5) / (35 + 5 + 277 + 78)
print(P_A)
P_B = (78 + 5) / (35 + 5 + 277 + 78)
print(P_B) 
print()
P_A_U_B = 5 / (35 + 5 + 277 + 78)
print(P_A_U_B)
P_A_B = 0.012658227848101266/ 0.21012658227848102
print(P_A_B)


Joint Probability
cardnumber=input("Enter number of Card ") 
cardcolor=input("Enter color of Card ")


pofA=4/52 
pofB=26/52

print("p(A)=>Probablility of drawing card with number ",cardnumber," =",round(pofA,2)) 
print("p(B)=>Probablility of drawing card with color ",cardcolor," =",round(pofB,2))
print("Joint Probablity of A and B = P(A) * P(B)") 
pAandB=round(pofA * pofB,2)
print("P(A and B)=",pAandB)
print("There are ",pAandB *100," % chances that of getting ",cardcolor, " card with number "
,cardnumber)

Aim:- Write a program for to implement Rule based system.
import spacy

# import the matcher
from spacy.matcher import Matcher

# load a model and create the nlp object
nlp = spacy.load('en_core_web_sm')

# Initialize the matcher with the shared vocab
matcher = Matcher(nlp.vocab)

# add the pattern to the matcher
pattern = [{'ORTH': 'iPhone'}, {'ORTH': 'X'}]
matcher.add('IPHONE_PATTERN', [pattern])

# process some text
doc = nlp("New iPhone X release date leaked")

# call the matcher on the doc matches = matcher(doc)
# iterate over the matches
for match_id, start, end in matcher(doc):
    # get the matched span
    matched_span = doc[start:end]
    print(matched_span.text)

# complex pattern Matching the lexical Attributes
pattern = [
    {'IS_DIGIT': True},
    {'LOWER': 'fifa'},
    {'LOWER': 'world'},
    {'LOWER': 'cup'},
    {'IS_PUNCT': True}
]
matcher.add('FIFA_WORLD_CUP', [pattern])
doc = nlp("2018 FIFA World Cup: France won!!!! ")
matches = matcher(doc)
# iterate over the matches
for match_id, start, end in matches:
    # get the matched span
    matched_span = doc[start:end]
    print(matched_span.text)

# Matching other token attributes
pattern = [
    {'LEMMA': 'love', 'POS': 'VERB'},
    {'POS': 'NOUN'}
]
matcher.add('LEMA_NOUN', [pattern])
doc = nlp("I loved dogs but now I love cats more.")
matches = matcher(doc)

# iterate over the matches
for match_id, start, end in matches:
    # get the matched span
    matched_span = doc[start:end]
    print(matched_span.text)

# Using operators and quantifiers
pattern = [
    {'LEMMA': 'buy'},
    {'POS': 'DET', 'OP': '?'},  # optional: match 0 or 1 times
    {'POS': 'NOUN'}
]
matcher.add('OPERATOR_QUANTIFIER', [pattern])
doc = nlp("I bought a smartphone. Now I'm buying apps.")
matches = matcher(doc)
# iterate over the matches
for match_id, start, end in matches:
    # get the matched span
    matched_span = doc[start:end]
    print(matched_span.text)


Supervised Learning –
import random
from sklearn.linear_model import LinearRegression

# Create an empty list for the feature data set 'X' and the target data set 'y'
feature_set = []
target_set = []

# get the number of rows wanted for the data set
number_of_rows = 200

# limit the possible values in the data set
random_number_limit = 2000

# Create the training data set
# Create and append a randomly generated data set to the input and output
for i in range(0, number_of_rows):
    x = random.randint(0, random_number_limit)
    y = random.randint(0, random_number_limit)
    z = random.randint(0, random_number_limit)
    print("x=", x, "\ty=", y, "\tz=", z)
    function = (10 * x) + (2 * y) + (3 * z)
    feature_set.append([x, y, z])
    target_set.append(function)

model = LinearRegression()

# Create a linear regression object/model
model.fit(feature_set, target_set)

test_set = [[193, 1651, 983]]
prediction = model.predict(test_set)

print('Prediction:', prediction, '\tCoefficient:', model.coef_)

Un – supervised Learning -
# Importing Modules
from sklearn import datasets
import matplotlib.pyplot as plt

# Loading dataset
iris_df = datasets.load_iris()

# Available methods on dataset
print(dir(iris_df))

# Features
print(iris_df.feature_names)

# Targets
print(iris_df.target)

# Target Names
print(iris_df.target_names)

label = {0: 'red', 1: 'blue', 2: 'green'}

# Dataset Slicing
x_axis = iris_df.data[:, 0]  # Sepal Length
y_axis = iris_df.data[:, 2]  # Sepal Width

# Plotting
plt.scatter(x_axis, y_axis, c=iris_df.target)
plt.show()


Implement K-means algorithm using Python

import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import MinMaxScaler
import seaborn as sns
import matplotlib.pyplot as plt

%matplotlib inline

# Load the train and test datasets to create two DataFrames
train_url = "http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/train.csv"
train = pd.read_csv(train_url)

test_url = "http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/test.csv"
test = pd.read_csv(test_url)

print("Train dataset:")
print(train.head())

print("\nTest dataset:")
print(test.head())

print("***** Train_Set *****")
print(train.describe())
print("\n")
print("***** Test_Set *****")
print(test.describe())

print(train.columns.values)

# For the train set
print("*****In the train set*****")
print(train.isna().sum())
print("\n")
print("*****In the test set*****")
print(test.isna().sum())

train.fillna(train.mean(), inplace=True)

test.fillna(test.mean(), inplace=True)

print(train.isna().sum())
print(test.isna().sum())

train['Ticket'].head()

train['Cabin'].head()

train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)

train[["Sex", "Survived"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)

train[["SibSp", "Survived"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)

g = sns.FacetGrid(train, col='Survived')
g.map(plt.hist, 'Age', bins=20)

grid = sns.FacetGrid(train, col='Survived', row='Pclass', height=2.2, aspect=1.6)
grid.map(plt.hist, 'Age', alpha=.5, bins=20)
grid.add_legend();

train.info()

train = train.drop(['Name','Ticket', 'Cabin','Embarked'], axis=1)
test = test.drop(['Name','Ticket', 'Cabin','Embarked'], axis=1)

labelEncoder = LabelEncoder()
labelEncoder.fit(train['Sex'])
labelEncoder.fit(test['Sex'])
train['Sex'] = labelEncoder.transform(train['Sex'])
test['Sex'] = labelEncoder.transform(test['Sex'])

train.info()
test.info()

X = np.array(train.drop(['Survived'], 1).astype(float))
y = np.array(train['Survived'])

kmeans = KMeans(n_clusters=2)
kmeans.fit(X)

correct = 0
for i in range(len(X)):
    predict_me = np.array(X[i].astype(float))
    predict_me = predict_me.reshape(-1, len(predict_me))
    prediction = kmeans.predict(predict_me)
    if prediction[0] == y[i]: 
        correct += 1

print(correct/len(X))

kmeans = KMeans(n_clusters=2, max_iter=600, algorithm='auto')
kmeans.fit(X)

correct = 0
for i in range(len(X)):
    predict_me = np.array(X[i].astype(float))
    predict_me = predict_me.reshape(-1, len(predict_me))
    prediction = kmeans.predict(predict_me)
    if prediction[0] == y[i]: 
        correct += 1

print(correct/len(X))

scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)
kmeans.fit(X_scaled)

correct = 0
for i in range(len(X)):
    predict_me = np.array(X[i].astype(float))
    predict_me = predict_me.reshape(-1, len(predict_me))
    prediction = kmeans.predict(predict_me)
    if prediction[0] == y[i]: 
        correct += 1

print(correct/len(X))


PRACTICAL NO. 06

Aim: - Perform different operations on fuzzy set

1.	 Union: -

degree_of_membership(Y)= max(degree_of_membership(A), degree_of_membership(B))
Code: -

# Example to Demonstrate the Union of Two Fuzzy Sets
A = dict()
B = dict() Y = dict()
A = {"a": 0.2, "b": 0.3, "c": 0.6, "d": 0.6}
B = {"a": 0.9, "b": 0.9, "c": 0.4, "d": 0.5}

print('The First Fuzzy Set is :', A) print('The Second Fuzzy Set is :', B)

for A_key, B_key in zip(A, B): A_value = A[A_key] B_value = B[B_key]
if A_value > B_value: Y[A_key] = A_value else:
Y[B_key] = B_value
print('Fuzzy Set Union is :', Y) Output :-

 
2.	 Intersection: -
degree_of_membership(Y)= min(degree_of_membership(A), degree_of_membership(B))

Code: -

# Example to Demonstrate Intersection of Two Fuzzy Sets
A = dict()
B = dict() Y = dict()
A = {"a": 0.2, "b": 0.3, "c": 0.6, "d": 0.6}
B = {"a": 0.9, "b": 0.9, "c": 0.4, "d": 0.5}

print('The First Fuzzy Set is :', A) print('The Second Fuzzy Set is :', B)

for A_key, B_key in zip(A, B):
A_value = A[A_key] B_value = B[B_key]
if A_value < B_value:
Y[A_key] = A_value else:
Y[B_key] = B_value print('Fuzzy Set Intersection is :', Y)
Output: -


3.	Complement : -
degree_of_membership(Y)= 1 - degree_of_membership(A)
Code: -

Y = dict()
 
A = {"a": 0.2, "b": 0.3, "c": 0.6, "d": 0.6}
print('The Fuzzy Set is :', A)

for A_key in A:
Y[A_key]= 1-A[A_key] print('Fuzzy Set Complement is :', Y) Output: -


4.	Difference: -
degree_of_membership(Y)= min(degree_of_membership(A), 1- degree_of_membership(B))

Code: -
A = dict()
B = dict() Y = dict()
A = {"a": 0.2, "b": 0.3, "c": 0.6, "d": 0.6}
B = {"a": 0.9, "b": 0.9, "c": 0.4, "d": 0.5}

print('The First Fuzzy Set is :', A) print('The Second Fuzzy Set is :', B)

for A_key, B_key in zip(A, B): A_value = A[A_key] B_value = B[B_key]
B_value = 1 - B_value

if A_value < B_value: Y[A_key] = A_value else:
Y[B_key] = B_value print('Fuzzy Set Difference is :', Y) 
